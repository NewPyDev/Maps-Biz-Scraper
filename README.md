# Business Scraper - Professional Lead Generation System

Professional Google Maps business lead generation system with Playwright, FastAPI, and smart proxy management.

## âœ¨ Features

- âœ… **Playwright-based scraping** - Reliable, modern browser automation
- âœ… **Smart proxy management** - Auto-detection, rotation, health tracking
- âœ… **FastAPI dashboard** - Real-time updates and job management
- âœ… **CSV/PDF export** - Professional reports with filtering
- âœ… **Job queue system** - Manage multiple scraping jobs
- âœ… **SQLite database** - Persistent storage with quality scoring
- âœ… **Environment-based config** - Type-safe configuration with `.env`

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Create virtual environment
uv venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Install packages
uv pip install -e ".[dev]"
```

### 2. Configure Environment

```bash
# Copy environment template
copy .env.example .env  # Windows
cp .env.example .env    # Linux/Mac

# Edit .env with your settings (optional)
```

### 3. Run Application

```bash
python app.py
```

### 4. Access Dashboard

Open http://localhost:8000 in your browser

## ğŸ“– Documentation

- **[Documentation Index](docs/README.md)** - All documentation
- **[Dashboard Guide](docs/guides/dashboard.md)** - Using the web interface
- **[CSV Import Guide](docs/guides/csv-import.md)** - Bulk job import
- **[PDF Generation Guide](docs/guides/pdf-generation.md)** - Export reports
- **[Architecture](docs/technical/architecture.md)** - System design
- **[Deployment Checklist](docs/deployment/checklist.md)** - Production deployment

## âš™ï¸ Configuration

All configuration is managed through the `.env` file. Key settings:

```bash
# Database
DATABASE_PATH=business_leads.db

# Scraping
MAX_RESULTS_PER_JOB=50
HEADLESS_MODE=false

# Proxy (optional - auto-detected)
PROXIES_FILE=proxies.txt

# Server
HOST=0.0.0.0
PORT=8000
```

See [`.env.example`](.env.example) for all available options.

## ğŸ”’ Proxy Support

The scraper includes smart proxy management:

- **Auto-detection** - Checks for `proxies.txt` automatically
- **Works with or without proxies** - No code changes needed
- **Rotation & health tracking** - Skips failed proxies
- **Multiple formats supported** - `ip:port:user:pass`, `http://user:pass@ip:port`

**To use proxies:**
1. Create `proxies.txt` in project root
2. Add proxies (one per line)
3. Run scraper - proxies automatically detected!

**To disable proxies:**
- Delete or rename `proxies.txt`

See [Smart Proxy Guide](docs/guides/proxy-setup.md) for details.

## ğŸ“ Project Structure

```
business-scraper/
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ proxy_manager.py       # Smart proxy system
â”œâ”€â”€ database_manager.py    # Database operations
â”œâ”€â”€ google_maps_scraper.py # Main scraper
â”œâ”€â”€ app.py                 # FastAPI application
â”œâ”€â”€ .env                   # Environment configuration
â”œâ”€â”€ .env.example           # Configuration template
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ guides/            # User guides
â”‚   â”œâ”€â”€ technical/         # Technical docs
â”‚   â””â”€â”€ deployment/        # Deployment guides
â””â”€â”€ templates/             # Web templates
```

## ğŸ§ª Development

```bash
# Run tests
pytest

# Format code
black .

# Lint code
ruff check .

# Type check
mypy .
```

## ğŸ“Š Tech Stack

- **Backend**: FastAPI, Pydantic
- **Scraping**: Playwright
- **Database**: SQLite
- **Export**: Pandas, ReportLab
- **Config**: Pydantic Settings, python-dotenv

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Please read the documentation first.

---

**Professional product ready for production use** ğŸš€
